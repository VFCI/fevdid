---
title: "Derivations for Max Share Identification Method"
author: "Matthew DeHaven"
date: "February 1, 2024"
---

Article explaining the mathematics behind the two key `fevdid` functions:

- `id_fevdfd()`
- `id_fevdtd()`

## Structural Vector Autoregression (SVAR)

A SVAR(p) model with $p$ lags, for a vector of variables $y_t$,
assumes the data generating process is accurately represented as,
^[Notation and setup follows Chapter 1: Introduction from Kilian and Lutkepohl (2017)]

$$
B_0 y_t = B_1 y_{t-1} + ... + B_p y_{t-p} + w_t
$$

where $w_t$ are mean zero structural shocks, with a serially uncorrelated diagonal covariance matrix of $\Sigma_w = E[w_t w_t]$,

and $B_i$ are matrices of coefficients.

Empirically, however, only the following $A_i$ matrices of coefficients and $u_t$ vector of reduced form residuals are observed,

$$
y_t = \underbrace{B_0^{-1}B_1}_{A_1} y_{t-1} + ... + \underbrace{B_0^{-1}B_p}_{A_p} y_{t-p} + \underbrace{B_0^{-1} w_t}_{u_t} 
\\
y_t = A_1 y_{t-1} + ... + A_p y_{t-p} + u_t 
$$

#### Identification Problem

We observe reduced form residuals, $u_t$, but want the structural shocks, $w_t$.

$$
u_t = B_0^{-1} w_t
$$

At this point, WLOG, assume that $\Sigma_w = I$.

This implies that $\Sigma_u = B_0^{-1} B_0^{-1^\prime}$.

In order to identify the structural shocks, we simply need to know the structural impact matrix, $B_0$, or equivalently, the inverse $B_0^{-1}$.

##### Choleskey Decomposition

We will not be using the Choleskey matrix as the identifying assumption, but it is still useful for expressing the identification problem.

Let $P$ be the lower triangular Choleksey decomposition of the matrix $\Sigma_u$.

Then,

$$
\Sigma_u =  B_0^{-1} B_0^{-1^\prime} = PQQ'P
$$

where $Q$ is an orthonormal matrix (i.e. $QQ' = I$ and $Q^{-1} = Q'$) also known as a rotation matrix.

Since $B_0^{-1} = PQ$ we can represent the structural shock indentification problem as,

$$
u_t = P Q w_t
$$

where $Q$ is an unknown rotational matrix and $P$ and $u_t$ are known.

### Impulse Response Functions (IRF) and Forecast Errors

It will be useful for the max share method to show the impulse response and forecast error definitions.

#### IRFs
IRFs give the responses of each variable in $y_t$ for any horizon $i$ to a one-time impulse at time $t$ to each structural shock, $w_t$,
$$
\Theta_i \equiv \frac{\partial y_{t+i}}{\partial w_t} \hspace{1cm} i = 0, 1, 2, ..., H
$$

The IRF for the response of variable $k$ to an impulse for structural shock $j$ at horizon $i$ is denoted,
$$
\theta_{kj,i} \equiv \frac{\partial y_{k, t+i}}{\partial w_{jt}}
$$

Let the impulse responses to the reduced form residuals be similarily denoted as,
$$
\Phi_i \equiv \frac{\partial y_{t+i}}{\partial u_t} \hspace{1cm} i = 0, 1, 2, ..., H
\\
\phi_{kj,i} \equiv \frac{\partial y_{k, t+i}}{\partial u_{jt}}
$$

And we can map between the two using the $B_0$ impact matrix,
$$
\Theta_i = \Phi_i B_0^{-1} = \Phi_i  P Q
\\
\theta_{kj,i} = [\Phi_i B_0^{-1}]_{kj} = [\Phi_i P Q]_{kj}
$$

Letting $M_{k*}$ denote the $k$^th^ row and $M_{*j}$ denote the $j$^th^ column for any matrix M, then

$$
\theta_{kj,i} = \Phi_{k*,i} B_{0,*j}^{-1} = \Phi_{k*,i} P Q_{*j}
$$

#### Forecast Errors

Let $F_{t+h}$ denote $h$-step ahead forecast errors,
$$
F_{t+h} \equiv y_{t+h} - y_{t+h|t}
$$

Which, for a VAR process, can be denoted in terms of the redcued form IRFs, $\Phi_i$,
$$
F_{t+h} = \sum_{i=0}^{h-1} \Phi_i u_{t+h-i} = \sum_{i=0}^{h-1} \Phi_i B_0^{-1} w_{t+h-i}
$$


#### Forecast Error Variance (FEV)
The FEV, also known as the predicted mean squared error, is then calculated as
$$
FEV_h \equiv E[F_{t+h}F_{t+h}^\prime] 
\\
= \sum_{i=0}^{h-1} \Phi_i \Sigma_u \Phi_i^\prime
= \sum_{i=0}^{h-1} \Phi_i B_0^{-1} B_0^{-1^\prime} \Phi_i^\prime 
= \sum_{i=0}^{h-1} [\Phi_i B_0^{-1}] [\Phi_i B_0^{-1}]^\prime
$$

The FEV for impulse $j$ contribution to variable $k$ is then denoted as,
$$
FEV_{kj,h} =  \sum_{i=0}^{h-1}  [\Phi_i B_0^{-1}]_{jk} [\Phi_i B_0^{-1}]_{jk}^\prime
\\
= \sum_{i=0}^{h-1} \Phi_{k*,i} P Q_{*j} [\Phi_{k*,i} P Q_{*j}]^\prime
\\
= \sum_{i=0}^{h-1} \Phi_{k*,i} P Q_{*j} Q_{*j}^\prime P^\prime \Phi_{k*,i}^\prime
$$

Since $\Phi_{k*,i} P Q_{*j}$ is a single number (not a matrix), we can rearrange to
$$
= \sum_{i=0}^{h-1} Q_{*j}^\prime P^\prime \Phi_{k*,i}^\prime \Phi_{k*,i} P Q_{*j}
\\
= Q_{*j}^\prime \sum_{i=0}^{h-1}\left[ P^\prime \Phi_{k*,i}^\prime \Phi_{k*,i} P \right] Q_{*j}
$$

## Max Share Identification Method - Time Domain

Pick a structural shock $j$ by choosing the weights for $B_{0,*j}^{-1}$ that maximize the forecast error variance for the horizon in $[h^-, h^+]$

Solve the maximization problem:
$$
\max_{B_{0,*j}^{-1}} \sum_{h^-}^{h^+} \text{FEV}_{kj,h}
\\
= \max_{B_{0,*j}^{-1}} B_{0,*j}^{-1\prime} \sum_{h^-}^{h^+} \sum_{i=0}^{h-1}\left[\Phi_{k*,i}^\prime \Phi_{k*,i}\right] B_{0,*j}^{-1}
$$

This is equivalent to solving
$$
\max_{Q_{*j}} Q_{*j}^\prime \sum_{h^-}^{h^+} \sum_{i=0}^{h-1}\left[P^\prime \Phi_{k*,i}^\prime \Phi_{k*,i} P\right] Q_{*j}
$$

Which is maximized when $Q_{*j}$ is the eigenvector associated with the largest eigenvalue of the matrix $\Lambda$,

$$
\Lambda \equiv \sum_{h^-}^{h^+} \sum_{i=0}^{h-1}\left[P^\prime \Phi_{k*,i}^\prime \Phi_{k*,i} P\right]
$$

Both the Choleskey matrix $P$ and the reduced form IRFs $\Phi_{k*,i}$ are known.

---

## Simplifying VAR Representations

It is useful to represent your VAR(p) process as a VAR(1) when implementing these identification methods. 
In addition, the moving average representation will make it easier to calculate the frequency domain forecast error variance.

#### Representing a VAR(p) process as a VAR(1)

Any VAR(p) can be represented as a VAR(1).
^[See page 25 of Killian and Lutkepohl.]

Start with a VAR(p) process with $K$ variables in $y_t$,
$$
y_t = A_1 y_{t-1} + ... + A_p y_{t-p} + u_t 
$$

then it can be represented as,
$$
\underbrace{Y_t}_{Kpx1} = \underbrace{\mathbf{A}}_{KpxKp} Y_{t-1} + \underbrace{U_t}_{Kpx1}
$$

where
$$
Y_t \equiv \begin{bmatrix}y_t^\prime \\ . . . \\ y_{t-p}^\prime\end{bmatrix}
, \hspace{1cm}
\mathbf{A} \equiv \begin{bmatrix}A_1 & A_2 & ... & A_{p-1} & A_p \\ I_K & 0 & ... & 0 & 0 \\ 0 & I_K & ... & 0 & 0 \\ ... & ... & ... & ... & ... \\ 0 & 0 & ... &  I_K & 0 \end{bmatrix}
, \hspace{1cm}
U_t \equiv \begin{bmatrix}u_t \\ 0 \\ ... \\ 0 \end{bmatrix}
$$

$I_K$ is simply an indentity matrix of dimension $K$.

The matrix $\mathbf{A}$ is called the companion of the VAR(p) model.

#### Moving Average Representation

Deriving the moving average representation MA($\infty$) is simple from the VAR(1) process, simply continously substitute,
$$
Y_t = \mathbf{A} Y_{t-1} + U_t
\\
= \sum_{i=0}^{\infty} \mathbf{A}^i U_{t-i}
$$

In order to get our original vector, $y_t$,
$$
y_t = \sum_{i=0}^{\infty} J \mathbf{A}^i J^\prime U_{t-i}
$$

where $J = [I_K, 0_{KxK(p-1)}]$.

This is equivalent to,

$$
y_t = A(L)^{-1} u_t
\\
= (I - \mathbf{A})^{-1} u_t
$$

where 

$$
A(L)^{-1} = \sum_{i=0}^{\infty} \Phi_i L^{i}
\\
\Phi_i = J \mathbf{A}^i J^\prime
$$

$A(L)$ is known as a matrix polynomial in the lag operator, $L$.

The $\Phi_i$ defined here are the reduced form IRFs that we saw before in the IRF section.

---

## Max Share Identification Method - Frequency Domain

#### Infinite Horizon FEV

The prediction error covariance matrix ($FEV_h$) converges to the unconditional covariance matrix, $\Gamma_y(0)$,  as $h\rightarrow\infty$.

$$
\lim_{h\rightarrow\infty} FEV_h \rightarrow \Gamma_y(0)
$$

where $\Gamma_y(h)$ is the sceond moment of the VAR process

$$
\Gamma_y(h) \equiv Cov(y_t, y_{t-h}) = E[y_t y_{t-h}^\prime] = \sum_{i=0}^{\infty} \Phi_{h+i} \Sigma_u \Phi_i
$$

This is not very surprising because we saw that,

$$
FEV_{h} = \sum_{i=0}^{h-1} \Phi_i \Sigma_u \Phi_i^\prime
$$

Using our MA($\infty$) representation, we can say that
$$
\Gamma_y(0) = Cov(y_t, y_t) = E[ A(L)^{-1} u_t u_t^\prime A(L)^{-1\prime} ] = A(L)^{-1} \Sigma_u A(L)^{-1\prime}
$$

#### Infinite Horizon Time Domain Max Share

If we wanted the structural shock $j$ that maximixes the infinited horizon FEV for variable $k$, we could then write that as...

$$
\max_{B_{0,j*}} FEV_{kj, \infty} 
\\
= \max_{B_{0,j*}} [A(L)^{-1} \Sigma_u A(L)^{-1\prime}]_{kj}
\\
= \max_{B_{0,j*}} A(L)^{-1} B_{0,j*}^{-1} B_{0,j*}^{-1}A(L)^{-1\prime}
\\
= \max_{Q_{j*}} A(L)^{-1}_{*k} P Q_{j*} Q^\prime_{j*} P^\prime A(L)^{-1\prime}_{*k}
\\
= \max_{Q_{j*}} Q^\prime_{j*} \left[ P^\prime A(L)^{-1\prime}_{*k} A(L)^{-1}_{*k} P \right] Q_{j*}
$$

#### Temp 

Pick a structural shock $j$ by choosing the weights for $B_{0,*j}^{-1}$ that maximize the forecast error variance for the frequencies in $[\omega^-, \omega^+]$

Solve the maximization problem:
$$
\max_{B_{0,*j}^{-1}} \int_{\omega^-}^{\omega^+} \text{FEV}_{kj,\omega} d\omega
$$

This is equivalent to solving
$$
 \max_{B_{0,*j}^{-1}} B_{0,*j}^{-1\prime} \int_{\omega^-}^{\omega^+} \Phi_{k*,\omega}^\prime \Phi_{k*,\omega} \ d\omega \ B_{0,*j}^{-1}
$$

where $\Phi_{k*,\omega}$ is the impulse response function for a specific frequency $\omega$.  The next sections show how to calculate this value.

### Solving for IRF in frequency space
Note: One approximate solution is to calculate the time domain IRF out to long horizon (say 1000 periods), then take the fourier transformation, keep only the frequencies you want, square the contributions, and maximize the real value portion.

#### Representing VAR(p) as a VAR(1)

First it's easiest to work with the VAR(1) process instead of the VAR(p)
^[see page 25 of Killian and Lutkepohl]

. . .

$$
Y_t = \upsilon + A Y_{t-1} + U_t
$$

. . .

#### MA($\infty$) Representation
Next, represent as a moving average.
^[see page 26 of Killian and Lutkepohl]

. . .

$$
y_t = C(L)^{-1} \upsilon + C(L)^{-1} u_t
$$

where $C(L)^{-1} \equiv \sum_{i=0}^{\infty} \phi_i L^i$

. . .

#### Calculating the spectrum for an MA($\infty$)
Now, we can calculate the spectrum using
^[See Hamilton, page 152]

. . .

$$
s_Y(\omega) = \frac{1}{2\pi} \sigma^2 C(e^{-i\omega})C(e^{-i\omega})
$$

The key here is that we end up getting to,
$$
C(e^{-i\omega}) = (I - A_1 e^{-i\omega})^{-1}
$$

which is essentially solving out for the entire path of IRFs by inverting, and making the Fourier transformation at the same time.

. . .

---

# Resources

Hamilton, James D. *Time Series Analsysis*. Chapter 6: Spectral Analysis. Pg 152 - 172.  In particular, page 154 for deriving the population spectrum for a MA(infinity) process.

Kilian, Lutz and Lutekepohl Helmut. *Structural Vector Autoregressive Analysis*. (2017). In particular,

- *Chapter 1: Introduction* for SVAR notation.
- *Chapter 2: Vector Autoregressive Models*. Pg 19 - .  Specifically, page 25 for representing a VAR(p) process as a VAR(1) process.

Angeletos, George-Marios, Fabrice Collard, and Harris Dellas. (2020). "Businsess Cycle Anatomy". American Economic Review, 110(10): 3030 - 3070.  In particular, pages 3036 - 3037 for derivations.